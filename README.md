# ğŸ¯ VisionAssist â€“ Voice-to-Vision AI System

**VisionAssist** is a multimodal AI system that combines **voice input**, **object detection** (YOLO), **language reasoning** (OpenAI GPT), and **text-to-speech** (Google TTS) to help users identify and locate objects in images using natural voice commands.

---

## ğŸ§  System Architecture

```
Voice Input â†’ Whisper ASR â†’ GPT-3.5 (Object Extraction) â†’ YOLO Object Detection
                    â†˜              â†˜
                   Fallback Logic    â†’ TTS Response
```

---

## ğŸ“¦ Modules Overview

| Module         | Description |
|----------------|-------------|
| `asr/`         | Transcribes voice input using OpenAI Whisper |
| `llm/`         | Extracts object name from transcribed query using OpenAI GPT |
| `detection/`   | Runs YOLO object detection and checks if object exists |
| `fallback/`    | Generates standard fallback response if object not found |
| `tts/`         | Converts final text response into speech (Google TTS) |
| `training/`    | YOLO dataset and training wrapper |
| `main.py`      | End-to-end orchestration script |

---

## ğŸš€ Setup & Installation

### ğŸ”§ Requirements
- Python 3.8+
- pip

### ğŸ“¥ Install Dependencies
```bash
pip install -r requirements.txt
```

### ğŸ”‘ Set up OpenAI Key
Export your key as an environment variable:
```bash
export OPENAI_API_KEY="your-api-key-here"
```

---

## â–¶ï¸ Run the System

```bash
python main.py
```

By default, it looks for:
- `sample.wav` â€“ voice command audio file
- `demo.jpg` â€“ input image for object detection

---

## ğŸ§ª Sample Input / Output

### ğŸ¤ Voice Command:
> â€œWhere is the red shoe?â€

### ğŸ§  LLM Extracts:
> `"red shoe"`

### ğŸ–¼ï¸ YOLO Detects:
> `"shoe detected at [x1, y1, x2, y2]"`

### ğŸ” If Not Found:
> Fallback: â€œSorry, I couldnâ€™t find the red shoe.â€

### ğŸ”Š Final Response:
> Spoken via Google TTS

---

## ğŸ‹ï¸â€â™‚ï¸ Train Your Own YOLO Model

Edit `training/custom.yaml` and place your dataset in:
```
training/dataset/images/train
training/dataset/labels/train
```

Then run:
```bash
python training/train.py
```

---

## ğŸ“„ License

MIT License Â© 2025 Naveen Rawat

---

## ğŸ™Œ Credits

- [YOLOv5](https://github.com/ultralytics/yolov5)
- [Whisper](https://github.com/openai/whisper)
- [OpenAI GPT](https://openai.com/)
- [Google TTS](https://pypi.org/project/gTTS/)